{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will investigate the housing price dataset from Bay Area Home Sales Database and Zillow to Predict The Bay Area’s Home Prices.\n",
    "* This dataset was based on the homes sold between January 2013 and December 2015.\n",
    "* Please use all the techniques we have learned in the class to preprocesss/clean the dataset.\n",
    "* You can drop redundant features.\n",
    "<p style=\"color:blue\"><b>final_data.csv</b></p>\n",
    "* Please apply the folowing two methods to Predict The Bay Area’s Home Prices.\n",
    "\n",
    "<h3>Method 1: Multiple Linear Regression</h3>\n",
    "* Bulding the optimal model using Automatic implementations of Backward Elimination\n",
    "```\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j] == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    "```\n",
    "* <mark>Split the dataset into training sets and test sets</mark>\n",
    "* Fit LinearRegression to the training sets \n",
    "* Print the Linear Regression R squared score on the test sets\n",
    "* Print the Linear Regression RMSE score on the test sets\n",
    "\n",
    "<h3>Method 2: Least Absolute Shrinkage and Selection Operator(Lasso)</h3>\n",
    "* Fit Lasso to the training sets. \n",
    "* Print the Lasso R squared score on the test sets\n",
    "* Print the Lasso RMSE score on the test sets\n",
    "\n",
    "<h3>Method 3: Decision Tree </h3>\n",
    "* Fit Decision Tree to the training set. \n",
    "* Print the Decision Tree R squared score on the test sets\n",
    "* Print the Decision Tree RMSE score on the test sets\n",
    "\n",
    "<h3>Method 4: Random Forest </h3>\n",
    "* Fit Random Forest to the training sets. \n",
    "* Print the Random Forest R squared score on the test sets\n",
    "* Print the Random Forest RMSE score on the test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import dataset \"final_data.csv\" in pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Dataset Features\n",
      "================\n",
      "Index(['Unnamed: 0', 'address', 'info', 'z_address', 'bathrooms', 'bedrooms',\n",
      "       'finishedsqft', 'lastsolddate', 'lastsoldprice', 'latitude',\n",
      "       'longitude', 'neighborhood', 'totalrooms', 'usecode', 'yearbuilt',\n",
      "       'zestimate', 'zindexvalue', 'zipcode', 'zpid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Importing pandas package to read the csv file\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"final_data.csv\")\n",
    "print(\"================\")\n",
    "print(\"Dataset Features\")\n",
    "print(\"================\")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Shape of the dataset\n",
      "====================\n",
      "(11330, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"====================\")\n",
    "print(\"Shape of the dataset\")\n",
    "print(\"====================\")\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Looking into the dataset\n",
      "========================\n",
      "   Unnamed: 0                             address  \\\n",
      "0           2  Address: 1160 Mission Street #2007   \n",
      "1           5       Address: 260 King Street #475   \n",
      "2           7     Address: 560 Missouri Street #B   \n",
      "3           9        Address: 350 Missouri Street   \n",
      "4          11         Address: 3658 Folsom Street   \n",
      "\n",
      "                                                info  \\\n",
      "0   San FranciscoSales price: 1300000Sales date: ...   \n",
      "1   San FranciscoSales price: 750000Sales date: 0...   \n",
      "2   San FranciscoSales price: 1495000Sales date: ...   \n",
      "3   San FranciscoSales price: 2700000Sales date: ...   \n",
      "4   San FranciscoSales price: 1530000Sales date: ...   \n",
      "\n",
      "                   z_address  bathrooms  bedrooms  finishedsqft lastsolddate  \\\n",
      "0  1160 Mission St UNIT 2007        2.0       2.0        1043.0   02/17/2016   \n",
      "1       260 King St UNIT 475        1.0       1.0         903.0   02/17/2016   \n",
      "2        560 Missouri St # B        4.0       3.0        1425.0   02/17/2016   \n",
      "3            350 Missouri St        3.0       3.0        2231.0   02/17/2016   \n",
      "4             3658 Folsom St        3.0       3.0        1300.0   02/17/2016   \n",
      "\n",
      "   lastsoldprice   latitude   longitude     neighborhood  totalrooms  \\\n",
      "0      1300000.0  37.778705 -122.412635  South of Market         4.0   \n",
      "1       750000.0  37.777641 -122.393417  South of Market         3.0   \n",
      "2      1495000.0  37.759198 -122.396516     Potrero Hill         6.0   \n",
      "3      2700000.0  37.761886 -122.396769     Potrero Hill        10.0   \n",
      "4      1530000.0  37.740795 -122.413453   Bernal Heights         4.0   \n",
      "\n",
      "        usecode  yearbuilt  zestimate zindexvalue  zipcode        zpid  \n",
      "0   Condominium     2007.0  1167508.0     975,700  94103.0  83152781.0  \n",
      "1   Condominium     2004.0   823719.0     975,700  94107.0  69819817.0  \n",
      "2   Condominium     2003.0  1708594.0   1,277,600  94107.0  64972847.0  \n",
      "3  SingleFamily     1927.0  2411236.0   1,277,600  94107.0  15149489.0  \n",
      "4  SingleFamily     1900.0  1918539.0   1,248,000  94110.0  15161978.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"========================\")\n",
    "print(\"Looking into the dataset\")\n",
    "print(\"========================\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data provided is the home prices in the San Francisco. As the info field location is San Francisco in the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Preprocess/Clean the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Checking the features data types\n",
      "================================\n",
      "Unnamed: 0         int64\n",
      "address           object\n",
      "info              object\n",
      "z_address         object\n",
      "bathrooms        float64\n",
      "bedrooms         float64\n",
      "finishedsqft     float64\n",
      "lastsolddate      object\n",
      "lastsoldprice    float64\n",
      "latitude         float64\n",
      "longitude        float64\n",
      "neighborhood      object\n",
      "totalrooms       float64\n",
      "usecode           object\n",
      "yearbuilt        float64\n",
      "zestimate        float64\n",
      "zindexvalue       object\n",
      "zipcode          float64\n",
      "zpid             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the data set for any incompactible data types for the features\n",
    "print(\"================================\")\n",
    "print(\"Checking the features data types\")\n",
    "print(\"================================\")\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, the feature \"lastsolddate\" doesn't have the required data type. Which we need to convert. Either use the astype() or to_datetime() for converting the \"lastsolddate\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Data of zindexvalue feature\n",
      "===========================\n",
      "  zindexvalue\n",
      "0     975,700\n",
      "1     975,700\n",
      "2   1,277,600\n",
      "3   1,277,600\n",
      "4   1,248,000\n"
     ]
    }
   ],
   "source": [
    "# Look into the data in the zindexvalue feature\n",
    "print(\"===========================\")\n",
    "print(\"Data of zindexvalue feature\")\n",
    "print(\"===========================\")\n",
    "print(dataset[[\"zindexvalue\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"zindexvalue\" feature contains the numeric data where the data type for this feature is defined as \"object\" which we need to convert to \"float\" data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Checking the features data types of the dataset after changing\n",
      "==============================================================\n",
      "Unnamed: 0                int64\n",
      "address                  object\n",
      "info                     object\n",
      "z_address                object\n",
      "bathrooms               float64\n",
      "bedrooms                float64\n",
      "finishedsqft            float64\n",
      "lastsolddate     datetime64[ns]\n",
      "lastsoldprice           float64\n",
      "latitude                float64\n",
      "longitude               float64\n",
      "neighborhood             object\n",
      "totalrooms              float64\n",
      "usecode                  object\n",
      "yearbuilt               float64\n",
      "zestimate               float64\n",
      "zindexvalue             float64\n",
      "zipcode                 float64\n",
      "zpid                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting the lastsolddate to datetime data type\n",
    "dataset[\"lastsolddate\"]=pd.to_datetime(dataset[\"lastsolddate\"])\n",
    "# Converting the zindexvalue to float\n",
    "# Getting this error while converting ValueError: could not convert string to float: '975,700' for this \n",
    "# replace the ',' with ''\n",
    "dataset[\"zindexvalue\"]=dataset[\"zindexvalue\"].str.replace(',','').astype(\"float\")\n",
    "# We can perform convertion in two steps or in one step as above\n",
    "# dataset[\"zindexvalue\"]=dataset[\"zindexvalue\"].str.replace(',','')\n",
    "# dataset[\"zindexvalue\"]=dataset[\"zindexvalue\"].astype(\"float\")\n",
    "# Checking the column types after changing the dtype of the zindexvalue\n",
    "print(\"==============================================================\")\n",
    "print(\"Checking the features data types of the dataset after changing\")\n",
    "print(\"==============================================================\")\n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "Checking if there are any null values in the dataset\n",
      "====================================================\n",
      "Unnamed: 0       0\n",
      "address          0\n",
      "info             0\n",
      "z_address        0\n",
      "bathrooms        0\n",
      "bedrooms         0\n",
      "finishedsqft     0\n",
      "lastsolddate     0\n",
      "lastsoldprice    0\n",
      "latitude         0\n",
      "longitude        0\n",
      "neighborhood     0\n",
      "totalrooms       0\n",
      "usecode          0\n",
      "yearbuilt        0\n",
      "zestimate        0\n",
      "zindexvalue      0\n",
      "zipcode          0\n",
      "zpid             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any missing values in the data set\n",
    "print(\"====================================================\")\n",
    "print(\"Checking if there are any null values in the dataset\")\n",
    "print(\"====================================================\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset doesn't have any missing values. Now we will extract year from the \"lastsolddate\" as we dont want the entire date. We'll call extracted new feature as \"lastsoldyear\" and convert the data type to float to match with the data type of \"yearbuilt\" fearure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "After extraction of the year from the lastsolddate\n",
      "==================================================\n",
      "  lastsolddate  lastsoldyear\n",
      "0   2016-02-17          2016\n",
      "1   2016-02-17          2016\n",
      "2   2016-02-17          2016\n",
      "3   2016-02-17          2016\n",
      "4   2016-02-17          2016\n"
     ]
    }
   ],
   "source": [
    "# Extract year from the date column\n",
    "dataset[\"lastsoldyear\"] = dataset[\"lastsolddate\"].apply(lambda row: row.year)\n",
    "# Print the \"lastsolddate\", \"lastsoldyear\"\n",
    "print(\"==================================================\")\n",
    "print(\"After extraction of the year from the lastsolddate\")\n",
    "print(\"==================================================\")\n",
    "print(dataset[[\"lastsolddate\",\"lastsoldyear\"]].head())\n",
    "# Convert the year(which is the lastsolddate) from int to float as the same type as yearbuilt\n",
    "dataset[\"lastsoldyear\"]=dataset[\"lastsoldyear\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop the features which are redundant and not useful. The dataset has one unnamed feature as we dont get any information from the feature drop that feature. When queried the features it is identified as \"Unnamed: 0\". So drop that feature. We may assume that feature contains the ID after removing the null values.\n",
    "2. The features addrees, z_address, latitude, longtitude, neighborhood, zipcode all talks about the location. As we want to estimate the price based on the neighborhood we will drop remaining features related to location. \n",
    "3. The info feature is broken down into features like bedrooms, bathrooms, lastsoldprice, lastsolddate, finishedsqft. It does not create the new feature for lotsize.\n",
    "4. The feature zestimate is the market price estimated by the zillow.\n",
    "5. zpid is the zillow property id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droopping the features. We will keep the z_address to find the median with respect to neighborhood\n",
    "to_drop=[\"address\",\"info\",\"lastsolddate\",\"latitude\",\"longitude\",\"Unnamed: 0\",\"zestimate\",\"zpid\",\"zipcode\"]\n",
    "dataset=dataset.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "Features of the dataset after removing\n",
      "======================================\n",
      "Index(['z_address', 'bathrooms', 'bedrooms', 'finishedsqft', 'lastsoldprice',\n",
      "       'neighborhood', 'totalrooms', 'usecode', 'yearbuilt', 'zindexvalue',\n",
      "       'lastsoldyear'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset columns after removing\n",
    "print(\"======================================\")\n",
    "print(\"Features of the dataset after removing\")\n",
    "print(\"======================================\")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the unique values in the \"usecode\" and \"neighborhood\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "usecode value_count\n",
      "===================\n",
      "SingleFamily        5803\n",
      "Condominium         4802\n",
      "MultiFamily2To4      486\n",
      "Duplex               146\n",
      "Townhouse             66\n",
      "Miscellaneous         17\n",
      "Apartment              3\n",
      "Cooperative            3\n",
      "Mobile                 2\n",
      "MultiFamily5Plus       2\n",
      "Name: usecode, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the value_counts() to check the unique value count for usecode data\n",
    "print(\"===================\")\n",
    "print(\"usecode value_count\")\n",
    "print(\"===================\")\n",
    "print(dataset[\"usecode\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "Total count of unique neighborhood value_count\n",
      "==============================================\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# Use the value_counts() and count() to check the count of unique neighborhood data\n",
    "print(\"==============================================\")\n",
    "print(\"Total count of unique neighborhood value_count\")\n",
    "print(\"==============================================\")\n",
    "print(dataset[\"neighborhood\"].value_counts().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different neighborhood as different price for the house. Find the price for per square feet. To calculate the price per square feet we divide the lastsoldprice with finishedsqft and store the result in the \"pps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"pps\"]=dataset[\"lastsoldprice\"]/dataset[\"finishedsqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Features of the dataset after calculating pps\n",
      "=============================================\n",
      "Index(['z_address', 'bathrooms', 'bedrooms', 'finishedsqft', 'lastsoldprice',\n",
      "       'neighborhood', 'totalrooms', 'usecode', 'yearbuilt', 'zindexvalue',\n",
      "       'lastsoldyear', 'pps'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset columns after calculating the price per square feet\n",
    "print(\"=============================================\")\n",
    "print(\"Features of the dataset after calculating pps\")\n",
    "print(\"=============================================\")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature \"usecode\" has categorical data which we need to encode for this we are using one-hot encoding technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Features after one-hot encoding for usecode\n",
      "===========================================\n",
      "Index(['z_address', 'bathrooms', 'bedrooms', 'finishedsqft', 'lastsoldprice',\n",
      "       'neighborhood', 'totalrooms', 'usecode', 'yearbuilt', 'zindexvalue',\n",
      "       'lastsoldyear', 'pps', 'Apartment', 'Condominium', 'Cooperative',\n",
      "       'Duplex', 'Miscellaneous', 'Mobile', 'MultiFamily2To4',\n",
      "       'MultiFamily5Plus', 'SingleFamily', 'Townhouse'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Use the get_dummies() to do one-hot encoding\n",
    "dataset_usecode_enc=pd.get_dummies(dataset[\"usecode\"])\n",
    "dataset = pd.concat([dataset, dataset_usecode_enc], axis=1)\n",
    "print(\"===========================================\")\n",
    "print(\"Features after one-hot encoding for usecode\")\n",
    "print(\"===========================================\")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature \"usecode\" is no longer needed after one-hot encoding so drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the usecode feature\n",
    "to_drop=[\"usecode\"]\n",
    "dataset=dataset.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the neighborhood based on the price per square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_value=dataset.groupby([\"neighborhood\"]).mean()[\"pps\"]\n",
    "mean_value=dataset.groupby([\"neighborhood\"]).mean()\n",
    "neighborhood_pps=mean_value[\"pps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_temp=pd.concat([neighborhood_pps],axis=1)\n",
    "dataset_temp[\"neighborhood\"]=dataset_temp.index\n",
    "dataset_temp.columns.values[0]=\"pps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the median of the neighborhood_pps by using the median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756.0\n"
     ]
    }
   ],
   "source": [
    "median_neighborhood_pps=neighborhood_pps.round().median()\n",
    "print(median_neighborhood_pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=dataset_temp[\"pps\"] < median_neighborhood_pps\n",
    "dataset1_value=dataset_temp[dataset1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2=dataset_temp[\"pps\"] >= median_neighborhood_pps\n",
    "dataset_2_temp = dataset_temp[dataset2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group(x):\n",
    "    if x in dataset1_value.index:\n",
    "        return 'lp'\n",
    "    else:\n",
    "        return 'hp'\n",
    "dataset['group'] = dataset[\"neighborhood\"].apply(get_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "Features of the dataset after adding group\n",
      "==========================================\n",
      "Index(['z_address', 'bathrooms', 'bedrooms', 'finishedsqft', 'lastsoldprice',\n",
      "       'neighborhood', 'totalrooms', 'yearbuilt', 'zindexvalue',\n",
      "       'lastsoldyear', 'pps', 'Apartment', 'Condominium', 'Cooperative',\n",
      "       'Duplex', 'Miscellaneous', 'Mobile', 'MultiFamily2To4',\n",
      "       'MultiFamily5Plus', 'SingleFamily', 'Townhouse', 'group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the features of the dataset\n",
    "print(\"==========================================\")\n",
    "print(\"Features of the dataset after adding group\")\n",
    "print(\"==========================================\")\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the value_counts() to count the unique values in the group feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp    6998\n",
      "lp    4332\n",
      "Name: group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"group\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_group_enc=pd.get_dummies(dataset[\"group\"])\n",
    "dataset= pd.concat([dataset, dataset_group_enc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the neighborhood and group feature as we one hot encoded into \"high_price\" and \"low_price\"\n",
    "to_drop=[\"group\",\"neighborhood\",\"pps\",\"z_address\"]\n",
    "dataset=dataset.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the final features and the shape of the dataset using the columns and shape attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Features of the final dataset\n",
      "=============================\n",
      "Index(['bathrooms', 'bedrooms', 'finishedsqft', 'lastsoldprice', 'totalrooms',\n",
      "       'yearbuilt', 'zindexvalue', 'lastsoldyear', 'Apartment', 'Condominium',\n",
      "       'Cooperative', 'Duplex', 'Miscellaneous', 'Mobile', 'MultiFamily2To4',\n",
      "       'MultiFamily5Plus', 'SingleFamily', 'Townhouse', 'hp', 'lp'],\n",
      "      dtype='object')\n",
      "==========================\n",
      "Shape of the final dataset\n",
      "==========================\n",
      "(11330, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"=============================\")\n",
    "print(\"Features of the final dataset\")\n",
    "print(\"=============================\")\n",
    "print(dataset.columns)\n",
    "print(\"==========================\")\n",
    "print(\"Shape of the final dataset\")\n",
    "print(\"==========================\")\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('lastsoldprice', axis=1)\n",
    "y = dataset['lastsoldprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Score of the train sets\n",
      "=======================\n",
      "0.24479227962810404\n",
      "======================\n",
      "Score of the test sets\n",
      "======================\n",
      "0.016590187080833037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "# Print the score of knn on the train and test sets\n",
    "print(\"=======================\")\n",
    "print(\"Score of the train sets\")\n",
    "print(\"=======================\")\n",
    "print(knn.score(train_X, train_y))\n",
    "print(\"======================\")\n",
    "print(\"Score of the test sets\")\n",
    "print(\"======================\")\n",
    "print(knn.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method 1: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the backward selection for identifying the potential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy package to calculate the RMSE\n",
    "import numpy as np\n",
    "# Import the mean_squared_error from sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the automatic implementation of Backward elimination\n",
    "def backwardElimination(x, sl):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j] == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "    regressor_OLS.summary()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulding the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((11330,1)), values = X, axis = 1)\n",
    "SL = 0.05\n",
    "X_Modeled = backwardElimination(X, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Multi Linear Regression R Squared\n",
      "=================================\n",
      "Multi Linear Regression R squared\": 0.5880\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into training and test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_Modeled, y, test_size = 0.3, random_state = 0)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(train_X, train_y)\n",
    "print(\"=================================\")\n",
    "print(\"Multi Linear Regression R Squared\")\n",
    "print(\"=================================\")\n",
    "print('Multi Linear Regression R squared\": %.4f' % regressor.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the RMSE for the Multi linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Multi Linear Regression RMSE\n",
      "============================\n",
      "Multi Linear Regression RMSE: 597482.6651\n"
     ]
    }
   ],
   "source": [
    "# Calculate root-mean-square error (RMSE). Predict the test results\n",
    "y_pred = regressor.predict(test_X)\n",
    "lin_mse = mean_squared_error(y_pred, test_y)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"============================\")\n",
    "print(\"Multi Linear Regression RMSE\")\n",
    "print(\"============================\")\n",
    "print('Multi Linear Regression RMSE: %.4f' % lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below train_test_split is used for LASSO, Decision Tree Regression and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 2: Least Absolute Shrinkage and Selection Operator(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Lasso Regression R Squared\n",
      "==========================\n",
      "Lasso Regression R Squared: 0.5691\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lasso=linear_model.Lasso(alpha=1000,max_iter=1e4)\n",
    "lasso.fit(train_X,train_y)\n",
    "print(\"==========================\")\n",
    "print(\"Lasso Regression R Squared\")\n",
    "print(\"==========================\")\n",
    "print('Lasso Regression R Squared: %.4f'%lasso.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Lasso Regression RMSE\n",
      "=====================\n",
      "Lasso Regression RMSE: 611030.0425\n"
     ]
    }
   ],
   "source": [
    "# Calculate root-mean-square error (RMSE)\n",
    "y_pred = lasso.predict(test_X)\n",
    "lin_mse = mean_squared_error(y_pred, test_y)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(\"=====================\")\n",
    "print(\"Lasso Regression RMSE\")\n",
    "print(\"=====================\")\n",
    "print('Lasso Regression RMSE: %.4f' % lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Method 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "Decision Tree Regression R Squared\n",
      "==================================\n",
      "Decision Tree Regression R squared: 0.4190\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor_decision=DecisionTreeRegressor(random_state=0)\n",
    "regressor_decision.fit(train_X,train_y)\n",
    "print(\"==================================\")\n",
    "print(\"Decision Tree Regression R Squared\")\n",
    "print(\"==================================\")\n",
    "print('Decision Tree Regression R squared: %.4f'%regressor_decision.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================\n",
      "Decision Tree Regression RMSE\n",
      "=============================\n",
      "Decision Tree Regression RMSE: 709507.0142\n"
     ]
    }
   ],
   "source": [
    "# Calculate root-mean-square  error(RMSE)\n",
    "y_pred=regressor_decision.predict(test_X)\n",
    "lin_mse=mean_squared_error(y_pred,test_y)\n",
    "lin_rmse=np.sqrt(lin_mse)\n",
    "print(\"=============================\")\n",
    "print(\"Decision Tree Regression RMSE\")\n",
    "print(\"=============================\")\n",
    "print('Decision Tree Regression RMSE: %.4f' % lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "Random Forest R Squared\n",
      "=======================\n",
      "Random Forest R squared: 0.7175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg=RandomForestRegressor(n_estimators=1000,random_state=0)\n",
    "forest_reg.fit(train_X,train_y)\n",
    "print(\"=======================\")\n",
    "print(\"Random Forest R Squared\")\n",
    "print(\"=======================\")\n",
    "print('Random Forest R squared: %.4f'%forest_reg.score(test_X,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Random Forest RMSE\n",
      "==================\n",
      "Random Forest RMSE: 494732.5933\n"
     ]
    }
   ],
   "source": [
    "# Calculate root-mean-square  error(RMSE)\n",
    "y_pred=forest_reg.predict(test_X)\n",
    "forest_mse=mean_squared_error(y_pred,test_y)\n",
    "forest_rmse=np.sqrt(forest_mse)\n",
    "print(\"==================\")\n",
    "print(\"Random Forest RMSE\")\n",
    "print(\"==================\")\n",
    "print('Random Forest RMSE: %.4f'%forest_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Data Set Prediction Results Comparison Table of Method 1, Method 2, Method 3 and Method 4\n",
    "* Please fill in your results to the following table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "    <tr>\n",
    "    <th colspan=\"4\">Predict The Bay Area’s Home Prices</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <th> </th>\n",
    "    <th>Multiple Linear Regression</th>\n",
    "    <th>Lasso</th>\n",
    "    <th>Decision Tree</th>\n",
    "    <th>Random Forest</th>\n",
    "    </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "    <tr>\n",
    "        <th>R Squared Score</th>\n",
    "        <td> 0.5880 </td>\n",
    "        <td> 0.5691 </td>\n",
    "        <td> 0.4190 </td>\n",
    "        <td> 0.7175 </td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "         <th>RMSE</th>\n",
    "        <td> 597482.6651 </td>\n",
    "        <td> 611030.0425 </td>\n",
    "        <td> 709507.0142 </td>\n",
    "        <td> 494732.5933 </td>\n",
    "    </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
